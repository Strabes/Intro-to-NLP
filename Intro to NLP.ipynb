{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Natural Language Processing - Motivating Tasks\n",
    "2. Classical NLP\n",
    "    - Processing text for machine learning\n",
    "    - Text Classification\n",
    "    - Topic Modeling\n",
    "3. Modern NLP - State of the Art models using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Natural Language Processing\n",
    "\n",
    "Natural Language Processing is a field combining linguistics and computer science to analyze natural language data and perform various tasks.\n",
    "\n",
    "NLP is a broad topic that covers many different tasks. Common tasks include:\n",
    "\n",
    "1. Text Classification - Predict the topic of a news article from a predefined set of topics.\n",
    "2. Text Regression - Given the text of a review on Amazon, predict the number of stars.\n",
    "2. Named Entity Recognition - If \"apple\" is used in a sentence does it refer to fruit or a company?\n",
    "3. Question Answering - Given a context text, answer a question about it.\n",
    "4. Text Summarization - Produce a summary of a given text.\n",
    "5. Translation - Translate English to Spanish\n",
    "6. Text Generation - Given a prompt, write a story.\n",
    "7. Dialogue State Tracking - Given a conversation, record key facts about it.\n",
    "8. Topic modeling - Given a corpus of texts, discover common topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set up Google Colab runtime\n",
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Setting up Google Colab... \")\n",
    "    !git clone https://github.com/Strabes/Intro-to-NLP.git intro-to-nlp\n",
    "    %cd intro-to-nlp\n",
    "    from install import install_requirements\n",
    "    install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\grego\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 31.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling band of ultra-cynics, are seeing green again.\n",
      "--------------------------------------------------\n",
      "Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group, which has a reputation for making well-timed and occasionally controversial plays in the defense industry, has quietly placed its bets on another part of the market.\n",
      "--------------------------------------------------\n",
      "Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries about the economy and the outlook for earnings are expected to hang over the stock market next week during the depth of the summer doldrums.\n",
      "--------------------------------------------------\n",
      "Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export flows from the main pipeline in southern Iraq after intelligence showed a rebel militia could strike infrastructure, an oil official said on Saturday.\n",
      "--------------------------------------------------\n",
      "Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\n"
     ]
    }
   ],
   "source": [
    "for text in dataset[\"train\"][\"text\"][:5]:\n",
    "    print(\"-\"*50)\n",
    "    print(text.replace(\"\\\\\",\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP requires translating natural language documents to numeric representations and performing computations on these representations. The first step to **encoding** documents into numeric representations is breaking the documents down into smaller units via **tokenization**. One obvious method of tokenization is **work tokenization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      " ==> \n",
      "'Wall', 'St.', 'Bears', 'Claw', 'Back', 'Into', 'the', 'Black', '(', 'Reuters', ')', 'Reuters', '-', 'Short-sellers', ',', 'Wall', 'Street', ''s', 'dwindling', 'band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "example = dataset[\"train\"][\"text\"][0]\n",
    "\n",
    "def word_tokenize(text):\n",
    "    x = nltk.word_tokenize(text.replace(\"\\\\\",\" \"))\n",
    "    return x\n",
    "\n",
    "example_tokenized = word_tokenize(example)\n",
    "\n",
    "print(example + \"\\n ==> \")\n",
    "print(\", \".join([f\"'{t}'\" for t in example_tokenized]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many traditional statistical and machine learning models expect data to be in a tabular format where columns correspond to specific features and rows correspond to individual observations (in the case of NLP, each document is treated as an individual observation).\n",
    "\n",
    "The most common method of transforming a corpus of documents into a tabular format is **bag of words** where each column in the table represents a given word (token) and the entry in row i, column j is the count of times word j occurs in document i. We usually only create columns for the most common words, say the top 1000 words occurring in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>$</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>''</th>\n",
       "      <th>'s</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>...</th>\n",
       "      <th>was</th>\n",
       "      <th>week</th>\n",
       "      <th>what</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #  $  &  '  ''  's  (  )  ,  -  ...  was  week  what  which  who  will  \\\n",
       "0    0  0  0  0   0   1  1  1  2  1  ...    0     0     0      0    0     0   \n",
       "1    0  0  0  0   0   0  1  1  2  1  ...    0     0     0      0    0     0   \n",
       "2    0  0  0  1   0   0  1  1  0  1  ...    0     1     0      0    0     0   \n",
       "3    0  0  0  0   0   0  1  1  1  1  ...    0     0     0      0    0     0   \n",
       "4    0  0  0  0   0   0  1  1  3  1  ...    0     0     0      0    0     0   \n",
       "..  .. .. .. ..  ..  .. .. .. .. ..  ...  ...   ...   ...    ...  ...   ...   \n",
       "995  0  0  0  0   0   0  1  1  1  1  ...    0     0     0      0    0     0   \n",
       "996  0  0  0  0   0   0  1  1  0  1  ...    0     0     0      0    0     0   \n",
       "997  0  0  0  0   0   0  1  1  2  1  ...    0     1     0      0    0     0   \n",
       "998  0  0  0  0   0   2  1  1  3  0  ...    0     0     0      0    0     0   \n",
       "999  0  0  0  0   0   0  2  2  3  1  ...    0     0     0      0    0     0   \n",
       "\n",
       "     with  world  year  you  \n",
       "0       0      0     0    0  \n",
       "1       0      0     0    0  \n",
       "2       0      0     0    0  \n",
       "3       0      0     0    0  \n",
       "4       0      1     0    0  \n",
       "..    ...    ...   ...  ...  \n",
       "995     0      0     0    0  \n",
       "996     0      0     0    0  \n",
       "997     1      0     0    0  \n",
       "998     1      0     0    0  \n",
       "999     0      1     0    0  \n",
       "\n",
       "[1000 rows x 100 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=word_tokenize,max_features=100)\n",
    "\n",
    "count_vectorizer.fit(dataset[\"train\"][\"text\"][:1000])\n",
    "\n",
    "pd.DataFrame(count_vectorizer.transform(dataset[\"train\"][\"text\"][:1000]).toarray(),\n",
    "columns = count_vectorizer.get_feature_names_out().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>according</th>\n",
       "      <th>afp</th>\n",
       "      <th>ap</th>\n",
       "      <th>athens</th>\n",
       "      <th>billion</th>\n",
       "      <th>bush</th>\n",
       "      <th>charley</th>\n",
       "      <th>chavez</th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>...</th>\n",
       "      <th>web</th>\n",
       "      <th>week</th>\n",
       "      <th>win</th>\n",
       "      <th>windows</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     according  afp  ap  athens  billion  bush  charley  chavez  city  \\\n",
       "0            0    0   0       0        0     0        0       0     0   \n",
       "1            0    0   0       0        0     0        0       0     0   \n",
       "2            0    0   0       0        0     0        0       0     0   \n",
       "3            0    0   0       0        0     0        0       0     0   \n",
       "4            0    2   0       0        0     0        0       0     0   \n",
       "..         ...  ...  ..     ...      ...   ...      ...     ...   ...   \n",
       "995          0    0   0       0        0     0        0       0     0   \n",
       "996          0    0   0       0        0     0        0       0     0   \n",
       "997          0    0   2       0        0     0        0       0     0   \n",
       "998          0    0   1       0        0     0        0       0     0   \n",
       "999          0    0   1       0        0     0        0       0     0   \n",
       "\n",
       "     company  ...  web  week  win  windows  work  world  year  years  \\\n",
       "0          0  ...    0     0    0        0     0      0     0      0   \n",
       "1          0  ...    0     0    0        0     0      0     0      0   \n",
       "2          0  ...    0     1    0        0     0      0     0      0   \n",
       "3          0  ...    0     0    0        0     0      0     0      0   \n",
       "4          0  ...    0     0    0        0     0      1     0      0   \n",
       "..       ...  ...  ...   ...  ...      ...   ...    ...   ...    ...   \n",
       "995        0  ...    0     0    0        0     0      0     0      0   \n",
       "996        0  ...    0     0    0        0     0      0     0      0   \n",
       "997        0  ...    0     1    0        0     0      0     0      0   \n",
       "998        0  ...    0     0    0        0     0      0     0      0   \n",
       "999        1  ...    0     0    0        0     0      1     0      0   \n",
       "\n",
       "     yesterday  york  \n",
       "0            0     0  \n",
       "1            0     0  \n",
       "2            0     0  \n",
       "3            0     0  \n",
       "4            0     0  \n",
       "..         ...   ...  \n",
       "995          0     1  \n",
       "996          0     1  \n",
       "997          0     0  \n",
       "998          0     0  \n",
       "999          0     0  \n",
       "\n",
       "[1000 rows x 100 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def word_tokenize(text):\n",
    "    x = nltk.word_tokenize(text.replace(\"\\\\\",\" \"))\n",
    "    # filter out tokens that don't contain at least\n",
    "    # two consecutive alpha-numeric characters\n",
    "    x = [t for t in x if re.search(\"[A-Za-z0-9]{2,}\",t)]\n",
    "    return [t.lower() for t in x]\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    tokenizer=word_tokenize,\n",
    "    max_features=100,\n",
    "    stop_words='english')\n",
    "\n",
    "count_vectorizer.fit(dataset[\"train\"][\"text\"][:1000])\n",
    "\n",
    "pd.DataFrame(count_vectorizer.transform(dataset[\"train\"][\"text\"][:1000]).toarray(),\n",
    "columns = count_vectorizer.get_feature_names_out().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='hello'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"[A-Za-z0-9]{2,}\",\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " ',': 1,\n",
       " '.': 2,\n",
       " 'a': 3,\n",
       " 'to': 4,\n",
       " 'of': 5,\n",
       " 'in': 6,\n",
       " 'and': 7,\n",
       " \"'s\": 8,\n",
       " 'for': 9,\n",
       " '(': 10,\n",
       " ')': 11,\n",
       " ';': 12,\n",
       " 'on': 13,\n",
       " 'that': 14,\n",
       " 'is': 15,\n",
       " '-': 16,\n",
       " 'ap': 17,\n",
       " 'it': 18,\n",
       " 'by': 19,\n",
       " \"''\": 20,\n",
       " '&': 21,\n",
       " 'as': 22,\n",
       " 'at': 23,\n",
       " 'with': 24,\n",
       " 'are': 25,\n",
       " ':': 26,\n",
       " 'from': 27,\n",
       " 'new': 28,\n",
       " '--': 29,\n",
       " '...': 30,\n",
       " 'its': 31,\n",
       " '``': 32,\n",
       " 'be': 33,\n",
       " 'this': 34,\n",
       " 'an': 35,\n",
       " 'reuters': 36,\n",
       " 'has': 37,\n",
       " 'but': 38,\n",
       " 'have': 39,\n",
       " 'google': 40,\n",
       " 'will': 41,\n",
       " '?': 42,\n",
       " 'lt': 43,\n",
       " 'gt': 44,\n",
       " 'i': 45,\n",
       " 'more': 46,\n",
       " \"'\": 47,\n",
       " 'they': 48,\n",
       " 'said': 49,\n",
       " 'you': 50,\n",
       " 'could': 51,\n",
       " 'was': 52,\n",
       " 'his': 53,\n",
       " 'can': 54,\n",
       " 'about': 55,\n",
       " 'their': 56,\n",
       " \"n't\": 57,\n",
       " 'first': 58,\n",
       " 'space': 59,\n",
       " 'after': 60,\n",
       " 'one': 61,\n",
       " 'up': 62,\n",
       " '#': 63,\n",
       " 'company': 64,\n",
       " 'space.com': 65,\n",
       " 'or': 66,\n",
       " 'into': 67,\n",
       " 'over': 68,\n",
       " 'who': 69,\n",
       " 'scientists': 70,\n",
       " 'than': 71,\n",
       " 'what': 72,\n",
       " 'not': 73,\n",
       " 'out': 74,\n",
       " 'all': 75,\n",
       " 'some': 76,\n",
       " 'software': 77,\n",
       " 'which': 78,\n",
       " 'off': 79,\n",
       " 'ipo': 80,\n",
       " 'if': 81,\n",
       " 'may': 82,\n",
       " 'he': 83,\n",
       " 'would': 84,\n",
       " 'year': 85,\n",
       " '$': 86,\n",
       " 'microsoft': 87,\n",
       " 'time': 88,\n",
       " 'team': 89,\n",
       " 'world': 90,\n",
       " 'says': 91,\n",
       " 'security': 92,\n",
       " 'inc.': 93,\n",
       " 'search': 94,\n",
       " 'your': 95,\n",
       " 'when': 96,\n",
       " 'been': 97,\n",
       " 'like': 98,\n",
       " 'nasa': 99,\n",
       " 'week': 100,\n",
       " 'last': 101,\n",
       " 'no': 102,\n",
       " 'do': 103,\n",
       " 'technology': 104,\n",
       " 'people': 105,\n",
       " 'friday': 106,\n",
       " 'public': 107,\n",
       " 'were': 108,\n",
       " 'market': 109,\n",
       " 'news': 110,\n",
       " 'how': 111,\n",
       " 'just': 112,\n",
       " 'had': 113,\n",
       " 'million': 114,\n",
       " 'service': 115,\n",
       " 'say': 116,\n",
       " 'thursday': 117,\n",
       " 'day': 118,\n",
       " 'there': 119,\n",
       " 'other': 120,\n",
       " '!': 121,\n",
       " 'most': 122,\n",
       " 'system': 123,\n",
       " 'get': 124,\n",
       " 'now': 125,\n",
       " 'group': 126,\n",
       " 'computer': 127,\n",
       " 'work': 128,\n",
       " 'web': 129,\n",
       " 'two': 130,\n",
       " 'online': 131,\n",
       " 'wednesday': 132,\n",
       " 'earth': 133,\n",
       " 'university': 134,\n",
       " 'olympic': 135,\n",
       " 'oil': 136,\n",
       " 'before': 137,\n",
       " 'down': 138,\n",
       " 'engine': 139,\n",
       " 'while': 140,\n",
       " 'plans': 141,\n",
       " 'good': 142,\n",
       " 'even': 143,\n",
       " 'we': 144,\n",
       " 'wireless': 145,\n",
       " 'experts': 146,\n",
       " 'windows': 147,\n",
       " 'next': 148,\n",
       " 'us': 149,\n",
       " 'through': 150,\n",
       " 'sunday': 151,\n",
       " 'u.s.': 152,\n",
       " 'because': 153,\n",
       " 'study': 154,\n",
       " 'stock': 155,\n",
       " 'show': 156,\n",
       " 'sales': 157,\n",
       " 'auction': 158,\n",
       " 'help': 159,\n",
       " 'playboy': 160,\n",
       " 'years': 161,\n",
       " 'final': 162,\n",
       " 'open': 163,\n",
       " 'quot': 164,\n",
       " 'today': 165,\n",
       " 'best': 166,\n",
       " 'apple': 167,\n",
       " '1': 168,\n",
       " 'using': 169,\n",
       " 'so': 170,\n",
       " 'night': 171,\n",
       " 'back': 172,\n",
       " 'latest': 173,\n",
       " 'my': 174,\n",
       " 'start': 175,\n",
       " 'these': 176,\n",
       " 'according': 177,\n",
       " 'interview': 178,\n",
       " 'companies': 179,\n",
       " 'against': 180,\n",
       " 'make': 181,\n",
       " 'customers': 182,\n",
       " 'around': 183,\n",
       " 'life': 184,\n",
       " 'does': 185,\n",
       " 'our': 186,\n",
       " 'times': 187,\n",
       " 'hubble': 188,\n",
       " 'mission': 189,\n",
       " 'way': 190,\n",
       " 'athens': 191,\n",
       " 'economy': 192,\n",
       " 'saturday': 193,\n",
       " 'york': 194,\n",
       " 'should': 195,\n",
       " 'offering': 196,\n",
       " 'japan': 197,\n",
       " 'found': 198,\n",
       " 'hp': 199,\n",
       " 'business': 200,\n",
       " 'sun': 201,\n",
       " 'any': 202,\n",
       " 'xp': 203,\n",
       " 'three': 204,\n",
       " 'dell': 205,\n",
       " 'money': 206,\n",
       " 'need': 207,\n",
       " 'press': 208,\n",
       " 'central': 209,\n",
       " 'also': 210,\n",
       " 'saudi': 211,\n",
       " 'researchers': 212,\n",
       " 'use': 213,\n",
       " 'state': 214,\n",
       " 'here': 215,\n",
       " 'digital': 216,\n",
       " 'national': 217,\n",
       " 'reported': 218,\n",
       " 'human': 219,\n",
       " 'star': 220,\n",
       " 'many': 221,\n",
       " 'san': 222,\n",
       " 'part': 223,\n",
       " 'prices': 224,\n",
       " 'government': 225,\n",
       " 'why': 226,\n",
       " 'south': 227,\n",
       " 'phone': 228,\n",
       " 'network': 229,\n",
       " 'go': 230,\n",
       " 'internet': 231,\n",
       " 'tech': 232,\n",
       " 'find': 233,\n",
       " '2004': 234,\n",
       " 'those': 235,\n",
       " 'ahead': 236,\n",
       " 'pc': 237,\n",
       " 'being': 238,\n",
       " 'dvd': 239,\n",
       " 'code': 240,\n",
       " 'young': 241,\n",
       " 'long': 242,\n",
       " 'moon': 243,\n",
       " \"'re\": 244,\n",
       " 'telescope': 245,\n",
       " 'lead': 246,\n",
       " 'washington': 247,\n",
       " '3': 248,\n",
       " 'ebay': 249,\n",
       " 'firm': 250,\n",
       " 'industry': 251,\n",
       " 'strike': 252,\n",
       " 'june': 253,\n",
       " 'little': 254,\n",
       " 'days': 255,\n",
       " 'only': 256,\n",
       " 'report': 257,\n",
       " 'magazine': 258,\n",
       " 'across': 259,\n",
       " 'looking': 260,\n",
       " 'close': 261,\n",
       " 'mobile': 262,\n",
       " 'them': 263,\n",
       " 'corp.': 264,\n",
       " 'city': 265,\n",
       " 'key': 266,\n",
       " 'home': 267,\n",
       " '5': 268,\n",
       " 'number': 269,\n",
       " 'officials': 270,\n",
       " 'information': 271,\n",
       " 'tuesday': 272,\n",
       " '3d': 273,\n",
       " 'still': 274,\n",
       " 'science': 275,\n",
       " 'astronauts': 276,\n",
       " 'something': 277,\n",
       " 'perseid': 278,\n",
       " 'meteor': 279,\n",
       " 'shower': 280,\n",
       " 'agency': 281,\n",
       " 'probe': 282,\n",
       " 'percent': 283,\n",
       " 'race': 284,\n",
       " 'without': 285,\n",
       " 'video': 286,\n",
       " 'game': 287,\n",
       " 'looks': 288,\n",
       " 'during': 289,\n",
       " 'record': 290,\n",
       " 'past': 291,\n",
       " 'net': 292,\n",
       " 'become': 293,\n",
       " 'less': 294,\n",
       " 'growth': 295,\n",
       " 'giant': 296,\n",
       " 'uk': 297,\n",
       " 'hope': 298,\n",
       " 'yesterday': 299,\n",
       " 'own': 300,\n",
       " 'sell': 301,\n",
       " 'used': 302,\n",
       " 'image': 303,\n",
       " 'really': 304,\n",
       " 'same': 305,\n",
       " 'systems': 306,\n",
       " 'too': 307,\n",
       " 'international': 308,\n",
       " 'plan': 309,\n",
       " 'issue': 310,\n",
       " 'high': 311,\n",
       " 'enough': 312,\n",
       " '10': 313,\n",
       " 'aol': 314,\n",
       " '151': 315,\n",
       " 'air': 316,\n",
       " 'station': 317,\n",
       " 'stars': 318,\n",
       " 'solar': 319,\n",
       " 'drug': 320,\n",
       " 'set': 321,\n",
       " 'largest': 322,\n",
       " 'north': 323,\n",
       " 'spacecraft': 324,\n",
       " 'course': 325,\n",
       " 'cell': 326,\n",
       " 'must': 327,\n",
       " 'java': 328,\n",
       " 'logger': 329,\n",
       " 'games': 330,\n",
       " 'yahoo': 331,\n",
       " 'craigslist': 332,\n",
       " '25': 333,\n",
       " 'release': 334,\n",
       " 'aug': 335,\n",
       " 'again': 336,\n",
       " 'earnings': 337,\n",
       " 'expected': 338,\n",
       " 'iraq': 339,\n",
       " 'afp': 340,\n",
       " '36': 341,\n",
       " 'billion': 342,\n",
       " 'real': 343,\n",
       " 'annual': 344,\n",
       " 'markets': 345,\n",
       " 'president': 346,\n",
       " 'initial': 347,\n",
       " 'data': 348,\n",
       " 'big': 349,\n",
       " 'such': 350,\n",
       " 'despite': 351,\n",
       " 'country': 352,\n",
       " 'cut': 353,\n",
       " 'second': 354,\n",
       " 'shares': 355,\n",
       " 'much': 356,\n",
       " 'takes': 357,\n",
       " 'pay': 358,\n",
       " 'running': 359,\n",
       " 'japanese': 360,\n",
       " 'e-mail': 361,\n",
       " 'ibm': 362,\n",
       " 'nearly': 363,\n",
       " 'share': 364,\n",
       " 'turned': 365,\n",
       " 'kerry': 366,\n",
       " 'month': 367,\n",
       " 'former': 368,\n",
       " 'working': 369,\n",
       " 'americans': 370,\n",
       " 'where': 371,\n",
       " 'american': 372,\n",
       " 'top': 373,\n",
       " 'know': 374,\n",
       " 'project': 375,\n",
       " 'version': 376,\n",
       " 'developers': 377,\n",
       " 'music': 378,\n",
       " 'offers': 379,\n",
       " 'offer': 380,\n",
       " 'send': 381,\n",
       " 'calls': 382,\n",
       " 'popular': 383,\n",
       " 'among': 384,\n",
       " 'store': 385,\n",
       " 'put': 386,\n",
       " 'full': 387,\n",
       " 'phones': 388,\n",
       " 'august': 389,\n",
       " 'likely': 390,\n",
       " 'ship': 391,\n",
       " 'rex': 392,\n",
       " 'research': 393,\n",
       " 'planets': 394,\n",
       " 'monday': 395,\n",
       " 'rocket': 396,\n",
       " 'called': 397,\n",
       " 'planet': 398,\n",
       " 'users': 399,\n",
       " 'manned': 400,\n",
       " 'launch': 401,\n",
       " 'problems': 402,\n",
       " 'change': 403,\n",
       " 'might': 404,\n",
       " 'saturn': 405,\n",
       " 'then': 406,\n",
       " 'announced': 407,\n",
       " 'region': 408,\n",
       " 'recent': 409,\n",
       " 'under': 410,\n",
       " 'article': 411,\n",
       " \"'m\": 412,\n",
       " 'blog': 413,\n",
       " 'stake': 414,\n",
       " 'win': 415,\n",
       " 'olympics': 416,\n",
       " 'b': 417,\n",
       " 'site': 418,\n",
       " 'avoid': 419,\n",
       " 'pro': 420,\n",
       " 'summer': 421,\n",
       " 'months': 422,\n",
       " 'retail': 423,\n",
       " 'claims': 424,\n",
       " 'drop': 425,\n",
       " 'thing': 426,\n",
       " 'gap': 427,\n",
       " 'think': 428,\n",
       " 'having': 429,\n",
       " 'season': 430,\n",
       " 'cause': 431,\n",
       " 'cost': 432,\n",
       " 'five': 433,\n",
       " 'quarter': 434,\n",
       " 'place': 435,\n",
       " 'ocean': 436,\n",
       " 'planning': 437,\n",
       " 'arabia': 438,\n",
       " 'bush': 439,\n",
       " 'john': 440,\n",
       " 'including': 441,\n",
       " 'chief': 442,\n",
       " 'away': 443,\n",
       " 'well': 444,\n",
       " 'four': 445,\n",
       " 'face': 446,\n",
       " 'although': 447,\n",
       " 'play': 448,\n",
       " 'download': 449,\n",
       " 'british': 450,\n",
       " 'future': 451,\n",
       " 'different': 452,\n",
       " 'office': 453,\n",
       " 'take': 454,\n",
       " 'instruments': 455,\n",
       " 'return': 456,\n",
       " 'source': 457,\n",
       " 'released': 458,\n",
       " 'made': 459,\n",
       " 'federal': 460,\n",
       " 'early': 461,\n",
       " 'operating': 462,\n",
       " 'force': 463,\n",
       " 'prize': 464,\n",
       " 'russian': 465,\n",
       " 'right': 466,\n",
       " 'until': 467,\n",
       " 'free': 468,\n",
       " 'never': 469,\n",
       " 'india': 470,\n",
       " 'very': 471,\n",
       " 'few': 472,\n",
       " 'climate': 473,\n",
       " 'feet': 474,\n",
       " 'spam': 475,\n",
       " 'server': 476,\n",
       " 'me': 477,\n",
       " 'al': 478,\n",
       " 'starts': 479,\n",
       " 'united': 480,\n",
       " 'ms': 481,\n",
       " 'her': 482,\n",
       " 'left': 483,\n",
       " 'chandra': 484,\n",
       " 'voip': 485,\n",
       " 'guilty': 486,\n",
       " 's': 487,\n",
       " 'phelps': 488,\n",
       " 'wall': 489,\n",
       " 'black': 490,\n",
       " 'making': 491,\n",
       " 'bit': 492,\n",
       " 'soon': 493,\n",
       " 'available': 494,\n",
       " 'highly': 495,\n",
       " 'trade': 496,\n",
       " 'growing': 497,\n",
       " 'kids': 498,\n",
       " 'rule': 499,\n",
       " 'power': 500,\n",
       " 'reason': 501,\n",
       " 'rival': 502,\n",
       " 'gets': 503,\n",
       " 'slow': 504,\n",
       " 'car': 505,\n",
       " 'korea': 506,\n",
       " 'begins': 507,\n",
       " 'jobs': 508,\n",
       " 'seven': 509,\n",
       " 'creating': 510,\n",
       " 'size': 511,\n",
       " 'thought': 512,\n",
       " 'legal': 513,\n",
       " 'between': 514,\n",
       " 'lynn': 515,\n",
       " 'global': 516,\n",
       " 'executive': 517,\n",
       " 'hurricane': 518,\n",
       " 'look': 519,\n",
       " 'asia': 520,\n",
       " 'want': 521,\n",
       " 'monkeys': 522,\n",
       " 'lot': 523,\n",
       " 'name': 524,\n",
       " 'product': 525,\n",
       " 'man': 526,\n",
       " 'leading': 527,\n",
       " 'enter': 528,\n",
       " 'florida': 529,\n",
       " 'services': 530,\n",
       " 'bea': 531,\n",
       " 'development': 532,\n",
       " 'lets': 533,\n",
       " 'health': 534,\n",
       " 'provide': 535,\n",
       " 'texas': 536,\n",
       " 'america': 537,\n",
       " 'late': 538,\n",
       " '20': 539,\n",
       " 'hacker': 540,\n",
       " 'streaming': 541,\n",
       " 'developing': 542,\n",
       " 'oracle': 543,\n",
       " 'seen': 544,\n",
       " 'judge': 545,\n",
       " 'took': 546,\n",
       " 'administration': 547,\n",
       " 'shuttle': 548,\n",
       " 'cargo': 549,\n",
       " 'food': 550,\n",
       " 'water': 551,\n",
       " 'raise': 552,\n",
       " 'display': 553,\n",
       " 'several': 554,\n",
       " 'x': 555,\n",
       " 'list': 556,\n",
       " 'australia': 557,\n",
       " 'common': 558,\n",
       " 'pacific': 559,\n",
       " 'mars': 560,\n",
       " 'millions': 561,\n",
       " 'website': 562,\n",
       " 'visual': 563,\n",
       " 'gold': 564,\n",
       " 'parents': 565,\n",
       " 'delays': 566,\n",
       " 'ancient': 567,\n",
       " 'california': 568,\n",
       " 'did': 569,\n",
       " 'attacks': 570,\n",
       " 'getting': 571,\n",
       " 'mozilla': 572,\n",
       " 'works': 573,\n",
       " 'needs': 574,\n",
       " 'faster': 575,\n",
       " 'keep': 576,\n",
       " 'linux': 577,\n",
       " '*': 578,\n",
       " 'ntp': 579,\n",
       " 'going': 580,\n",
       " 'servers': 581,\n",
       " 'states': 582,\n",
       " 'core': 583,\n",
       " 'behind': 584,\n",
       " 'ad': 585,\n",
       " 'began': 586,\n",
       " 'children': 587,\n",
       " 'los': 588,\n",
       " 'font': 589,\n",
       " 'face=': 590,\n",
       " 'verdana': 591,\n",
       " 'sans': 592,\n",
       " 'serif': 593,\n",
       " 'arial': 594,\n",
       " 'helvetica': 595,\n",
       " 'size=': 596,\n",
       " '-2': 597,\n",
       " 'color=': 598,\n",
       " '666666': 599,\n",
       " '/b': 600,\n",
       " '/font': 601,\n",
       " 'possible': 602,\n",
       " 'price': 603,\n",
       " 'forums': 604,\n",
       " 'test': 605,\n",
       " 'laboratory': 606,\n",
       " 'observatory': 607,\n",
       " 'access': 608,\n",
       " 'wi-fi': 609,\n",
       " 'fcc': 610,\n",
       " 'ipod': 611,\n",
       " 'player': 612,\n",
       " 'motion': 613,\n",
       " 'runs': 614,\n",
       " 'seeing': 615,\n",
       " 'another': 616,\n",
       " 'outlook': 617,\n",
       " 'southern': 618,\n",
       " 'infrastructure': 619,\n",
       " 'official': 620,\n",
       " 'maker': 621,\n",
       " 'fell': 622,\n",
       " 'general': 623,\n",
       " 'marketing': 624,\n",
       " 'head': 625,\n",
       " 'investors': 626,\n",
       " \"'ve\": 627,\n",
       " 'possibly': 628,\n",
       " 'faces': 629,\n",
       " 'bidding': 630,\n",
       " 'spending': 631,\n",
       " 'rates': 632,\n",
       " 'bank': 633,\n",
       " 'hits': 634,\n",
       " 'both': 635,\n",
       " 'survey': 636,\n",
       " 'drive': 637,\n",
       " 'hewlett-packard': 638,\n",
       " 'expectations': 639,\n",
       " 'aid': 640,\n",
       " 'darfur': 641,\n",
       " 'nuclear': 642,\n",
       " 'coast': 643,\n",
       " 'turn': 644,\n",
       " 'electronic': 645,\n",
       " 'application': 646,\n",
       " 'competition': 647,\n",
       " 'square': 648,\n",
       " 'planned': 649,\n",
       " 'taking': 650,\n",
       " 'sale': 651,\n",
       " 'loss': 652,\n",
       " 'results': 653,\n",
       " 'hot': 654,\n",
       " 'far': 655,\n",
       " 'movie': 656,\n",
       " 'added': 657,\n",
       " 'waters': 658,\n",
       " 'destinations': 659,\n",
       " 'pack': 660,\n",
       " 'projects': 661,\n",
       " 'ca': 662,\n",
       " 'founders': 663,\n",
       " 'mistakes': 664,\n",
       " 'current': 665,\n",
       " 'goes': 666,\n",
       " 'personal': 667,\n",
       " 'program': 668,\n",
       " 'shows': 669,\n",
       " 'sports': 670,\n",
       " 'format': 671,\n",
       " 'disc': 672,\n",
       " 'missing': 673,\n",
       " 'third': 674,\n",
       " 'products': 675,\n",
       " 'satellite': 676,\n",
       " 'scientific': 677,\n",
       " 'dedicated': 678,\n",
       " 'columbia': 679,\n",
       " 'died': 680,\n",
       " '2003': 681,\n",
       " 'fuel': 682,\n",
       " 'eat': 683,\n",
       " 'waves': 684,\n",
       " 't.': 685,\n",
       " 'gene': 686,\n",
       " 'license': 687,\n",
       " 'evidence': 688,\n",
       " 'comets': 689,\n",
       " 'massive': 690,\n",
       " 'finds': 691,\n",
       " 'taken': 692,\n",
       " 'once': 693,\n",
       " 'species': 694,\n",
       " 'trying': 695,\n",
       " 'meet': 696,\n",
       " 'miles': 697,\n",
       " 'since': 698,\n",
       " 'ago': 699,\n",
       " 'tropical': 700,\n",
       " 'rare': 701,\n",
       " 'edge': 702,\n",
       " 'eyes': 703,\n",
       " 'red': 704,\n",
       " 'images': 705,\n",
       " 'britain': 706,\n",
       " 'cloning': 707,\n",
       " 'stem': 708,\n",
       " 'range': 709,\n",
       " 'orbit': 710,\n",
       " 'major': 711,\n",
       " 'lunar': 712,\n",
       " 'death': 713,\n",
       " 'better': 714,\n",
       " 'deep': 715,\n",
       " 'weeks': 716,\n",
       " 'protect': 717,\n",
       " 'ecosystems': 718,\n",
       " 'warming': 719,\n",
       " 'birds': 720,\n",
       " 'learn': 721,\n",
       " 'qualifying': 722,\n",
       " 'add': 723,\n",
       " 'support': 724,\n",
       " 'together': 725,\n",
       " 'australian': 726,\n",
       " 'case': 727,\n",
       " 'create': 728,\n",
       " 'light': 729,\n",
       " 'applications': 730,\n",
       " 'static': 731,\n",
       " '=': 732,\n",
       " 'see': 733,\n",
       " '15': 734,\n",
       " 'liberty': 735,\n",
       " 'leader': 736,\n",
       " 'developed': 737,\n",
       " 'ever': 738,\n",
       " 'campaign': 739,\n",
       " 'order': 740,\n",
       " 'ie': 741,\n",
       " 'care': 742,\n",
       " 'strong': 743,\n",
       " 'broadband': 744,\n",
       " 'sp2': 745,\n",
       " 'update': 746,\n",
       " 'concerns': 747,\n",
       " 'quickly': 748,\n",
       " 'seattle': 749,\n",
       " 'settle': 750,\n",
       " 'buys': 751,\n",
       " 'gas': 752,\n",
       " 'clouds': 753,\n",
       " 'forests': 754,\n",
       " 'duke': 755,\n",
       " 'athletes': 756,\n",
       " 'lab': 757,\n",
       " 'progress': 758,\n",
       " 'surgery': 759,\n",
       " 'titan': 760,\n",
       " 'thousands': 761,\n",
       " 'earths': 762,\n",
       " 'brings': 763,\n",
       " 'healthdaynews': 764,\n",
       " 'shot': 765,\n",
       " 'vaccine': 766,\n",
       " 'virus': 767,\n",
       " 'saves': 768,\n",
       " 'devices': 769,\n",
       " 'chips': 770,\n",
       " 'shipping': 771,\n",
       " '90-nanometer': 772,\n",
       " 'production': 773,\n",
       " 'chairman': 774,\n",
       " 'http': 775,\n",
       " 'blaster': 776,\n",
       " 'jose': 777,\n",
       " 'michael': 778,\n",
       " 'registration': 779,\n",
       " '146': 780,\n",
       " 'freestyle': 781,\n",
       " 'track': 782,\n",
       " 'st.': 783,\n",
       " 'street': 784,\n",
       " 'band': 785,\n",
       " 'commercial': 786,\n",
       " 'private': 787,\n",
       " 'placed': 788,\n",
       " 'cloud': 789,\n",
       " 'stocks': 790,\n",
       " 'crude': 791,\n",
       " 'plus': 792,\n",
       " 'worries': 793,\n",
       " 'main': 794,\n",
       " 'authorities': 795,\n",
       " 'end': 796,\n",
       " 'near': 797,\n",
       " 'higher': 798,\n",
       " 'funds': 799,\n",
       " 'nation': 800,\n",
       " 'benefits': 801,\n",
       " 'buying': 802,\n",
       " 'opec': 803,\n",
       " 'warning': 804,\n",
       " 'fall': 805,\n",
       " 'foreign': 806,\n",
       " 'capital': 807,\n",
       " 'total': 808,\n",
       " 'itself': 809,\n",
       " 'underway': 810,\n",
       " 'later': 811,\n",
       " 'interest': 812,\n",
       " 'hand': 813,\n",
       " 'short': 814,\n",
       " 'indian': 815,\n",
       " 'sudan': 816,\n",
       " 'hit': 817,\n",
       " 'famous': 818,\n",
       " 'radio': 819,\n",
       " 'winning': 820,\n",
       " 'indians': 821,\n",
       " 'experimental': 822,\n",
       " 'heart': 823,\n",
       " 'buy': 824,\n",
       " 'bad': 825,\n",
       " 'success': 826,\n",
       " 'field': 827,\n",
       " 'gave': 828,\n",
       " 'beat': 829,\n",
       " 'democratic': 830,\n",
       " 'senior': 831,\n",
       " 'grant': 832,\n",
       " 'gateway': 833,\n",
       " 'block': 834,\n",
       " 'area': 835,\n",
       " 'given': 836,\n",
       " 'gives': 837,\n",
       " 'talks': 838,\n",
       " 'sees': 839,\n",
       " 'dying': 840,\n",
       " 'large': 841,\n",
       " 'charley': 842,\n",
       " 'king': 843,\n",
       " 'tough': 844,\n",
       " 'crowd': 845,\n",
       " 'wave': 846,\n",
       " 'doom': 847,\n",
       " 'channel': 848,\n",
       " 'chip': 849,\n",
       " 'problem': 850,\n",
       " 'includes': 851,\n",
       " 'edition': 852,\n",
       " 'republic': 853,\n",
       " 'means': 854,\n",
       " 'strange': 855,\n",
       " 'based': 856,\n",
       " 'model': 857,\n",
       " 'dropped': 858,\n",
       " 'consumer': 859,\n",
       " 'asian': 860,\n",
       " 'kind': 861,\n",
       " 'blues': 862,\n",
       " 'meets': 863,\n",
       " 'thailand': 864,\n",
       " 'vote': 865,\n",
       " 'let': 866,\n",
       " 'grew': 867,\n",
       " 'autodesk': 868,\n",
       " 'building': 869,\n",
       " 'filed': 870,\n",
       " 'due': 871,\n",
       " 'beats': 872,\n",
       " 'europe': 873,\n",
       " 'act': 874,\n",
       " 'links': 875,\n",
       " 'football': 876,\n",
       " 'guys': 877,\n",
       " 'speed': 878,\n",
       " 'cheap': 879,\n",
       " 'pcs': 880,\n",
       " 'approved': 881,\n",
       " 'dvds': 882,\n",
       " 'deals': 883,\n",
       " 'went': 884,\n",
       " 'norwegian': 885,\n",
       " 'apparently': 886,\n",
       " 'european': 887,\n",
       " '13': 888,\n",
       " 'documents': 889,\n",
       " 'storm': 890,\n",
       " 'politics': 891,\n",
       " 'advice': 892,\n",
       " 'along': 893,\n",
       " 'spurt': 894,\n",
       " 'party': 895,\n",
       " 'clone': 896,\n",
       " 'medical': 897,\n",
       " 'believe': 898,\n",
       " 'granted': 899,\n",
       " 'expedition': 900,\n",
       " 'overnight': 901,\n",
       " 'expect': 902,\n",
       " 'task': 903,\n",
       " 'rats': 904,\n",
       " 'save': 905,\n",
       " 'trouble': 906,\n",
       " 'form': 907,\n",
       " 'fight': 908,\n",
       " 'above': 909,\n",
       " 'whale': 910,\n",
       " 'beach': 911,\n",
       " 'fire': 912,\n",
       " 'genesis': 913,\n",
       " 'unusual': 914,\n",
       " 'question': 915,\n",
       " 'screen': 916,\n",
       " 'call': 917,\n",
       " 'temperatures': 918,\n",
       " 'great': 919,\n",
       " 'flight': 920,\n",
       " 'china': 921,\n",
       " '14': 922,\n",
       " 'potential': 923,\n",
       " 'risk': 924,\n",
       " 'dolphin': 925,\n",
       " 'carry': 926,\n",
       " 'canadian': 927,\n",
       " 'moving': 928,\n",
       " 'inside': 929,\n",
       " 'small': 930,\n",
       " 'nevada': 931,\n",
       " 'reach': 932,\n",
       " '40': 933,\n",
       " 'virginia': 934,\n",
       " 'mexico': 935,\n",
       " 'try': 936,\n",
       " 'marine': 937,\n",
       " 'revealed': 938,\n",
       " 'poachers': 939,\n",
       " 'mean': 940,\n",
       " 'baby': 941,\n",
       " 'him': 942,\n",
       " 'probably': 943,\n",
       " 'experience': 944,\n",
       " 'technologies': 945,\n",
       " 'explains': 946,\n",
       " 'worth': 947,\n",
       " 'violence': 948,\n",
       " 'police': 949,\n",
       " 'side': 950,\n",
       " 'idea': 951,\n",
       " 'via': 952,\n",
       " 'done': 953,\n",
       " 'role': 954,\n",
       " 'allows': 955,\n",
       " 'visit': 956,\n",
       " 'each': 957,\n",
       " 'evolution': 958,\n",
       " 'feature': 959,\n",
       " 'simcity': 960,\n",
       " 'special': 961,\n",
       " 'budget': 962,\n",
       " '/strong': 963,\n",
       " 'fake': 964,\n",
       " 'angeles': 965,\n",
       " 'dispute': 966,\n",
       " '2': 967,\n",
       " 'worms': 968,\n",
       " 'partners': 969,\n",
       " 'commission': 970,\n",
       " 'celestial': 971,\n",
       " 'bubble': 972,\n",
       " 'dust': 973,\n",
       " 'coral': 974,\n",
       " 'analysis': 975,\n",
       " 'cluster': 976,\n",
       " 'eight': 977,\n",
       " 'moves': 978,\n",
       " 'almost': 979,\n",
       " 'x-ray': 980,\n",
       " 'lunine': 981,\n",
       " 'planetary': 982,\n",
       " 'healthday': 983,\n",
       " 'reporter': 984,\n",
       " 'attack': 985,\n",
       " '18': 986,\n",
       " 'amd': 987,\n",
       " 'revenue': 988,\n",
       " 'workers': 989,\n",
       " 'id': 990,\n",
       " 'worm': 991,\n",
       " 'pleads': 992,\n",
       " 'variant': 993,\n",
       " 'battle': 994,\n",
       " 'palmsource': 995,\n",
       " 'tools': 996,\n",
       " 'inventory': 997,\n",
       " 'computers': 998,\n",
       " 'database': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def build_vocab(texts, tokenizer, max_tokens=10000):\n",
    "    counter = Counter(\n",
    "        token for tokens in map(tokenizer, texts)\n",
    "        for token in tokens)\n",
    "\n",
    "    return {t[0]:i for i,t in enumerate(counter.most_common(max_tokens))}\n",
    "\n",
    "vocab = build_vocab(dataset[\"train\"][\"text\"], word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key properties of a natural language is that its grammar is a discrete combinatorial system: From a small set of building blocks (words) we can build up an unlimited number of distinct combinations (sentences, paragraphs, documents) with distinct meanings. This poses a problem for computers because we need to translate natural languages to numeric representations and perform computations on them. With limited computational resources, we have to simplify the documents we process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.',\n",
       " \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\",\n",
       " 'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.',\n",
       " 'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"text\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "cc2077442d658f45778fa1e23b0ce166896ca90401b2e33d9c328547ed2859af"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
